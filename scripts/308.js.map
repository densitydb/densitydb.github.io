{"version":3,"file":"308.js","sources":["webpack://assets/./src/search.ts","webpack://assets/./src/data/type_to_priority.ts","webpack://assets/./src/navigation/links.ts","webpack://assets/./src/utils/DefaultMap.ts","webpack://assets/./src/utils/bitap.ts","webpack://assets/./src/utils/is_historical.ts","webpack://assets/./src/load_json.ts","webpack://assets/./src/searchWorker.ts","webpack://assets/webpack/runtime/define_property_getters","webpack://assets/webpack/runtime/ensure_chunk","webpack://assets/webpack/runtime/get javascript chunk filename","webpack://assets/webpack/runtime/global","webpack://assets/webpack/runtime/has_own_property","webpack://assets/webpack/runtime/on_chunk_loaded","webpack://assets/webpack/runtime/rspack_version","webpack://assets/webpack/runtime/startup_chunk_dependencies","webpack://assets/webpack/runtime/auto_public_path","webpack://assets/webpack/runtime/import_scripts_chunk_loading","webpack://assets/webpack/runtime/rspack_unique_id"],"sourcesContent":["import * as idb from 'idb'\n\nimport type_to_priority from './data/type_to_priority'\nimport { loadProtobuf } from './load_json'\nimport { DefaultMap } from './utils/DefaultMap'\nimport { bitap, bitapPerformance, bitCount, Haystack, toHaystack, toNeedle, toSignature } from './utils/bitap'\nimport { isHistoricalCD } from './utils/is_historical'\nimport { ISearchIndexMetadata } from './utils/protos'\n\nexport interface SearchResult {\n    longname: string\n    typeIndex: number\n}\n\nconst debugSearch: boolean = false\n\nfunction debug(arg: unknown): void {\n    if (debugSearch) {\n        // eslint-disable-next-line no-console -- Debug logging\n        console.log(arg)\n    }\n}\n\nconst debugSearchPerformance: boolean = false\n\nexport function debugPerformance(arg: unknown): void {\n    if (debugSearchPerformance) {\n        // eslint-disable-next-line no-console -- Debug logging\n        console.log(arg)\n    }\n}\n\nexport function normalize(a: string, handlePunctuation = true): string {\n    a = a.toLowerCase()\n    a = a.normalize('NFD')\n    a = a.replace(/[\\u0300-\\u036f]/g, '')\n    if (handlePunctuation) {\n        a = a.replace(/[,\\(\\)\\[\\]]/g, '')\n        a = a.replaceAll('-', ' ')\n    }\n    return a\n}\n\ninterface NormalizedSearchIndex {\n    entries: {\n        longname: string\n        tokens: Haystack[]\n        priority: number\n        signature: number\n        typeIndex: number\n    }[]\n    lengthOfLongestToken: number\n    maxPriority: number\n    mostTokens: number\n}\n\ninterface Result {\n    entry: NormalizedSearchIndex['entries'][number]\n    normalizedMatchScore: number // Lower is better ([0,1], where 0 is perfect match, and 1 is no matches)\n    normalizedPopulationRank: number // Lower is higher population (better) ([0,1], where 0 is highest population and 1 is lowest population)\n    normalizedPriority: number // Lower is better ([0,1] where 1 is least prioritized)\n    normalizedPositionScore: number // The absolute difference in position where tokens were found. Lower is better ([0, 1] where 0 is all tokens are in the right place, and 1 is all tokens are maximally distant in this result)\n    normalizedTokensWithIncompleteMatch: number // The number of tokens in the query that do NOT match \"completely\" (are the same length) with their tokens in the haystack. These matches may still have errors. ([0, 1], lower is better, where 0 means all tokens in the query match completely, and 1 means no tokens in the query match completely)\n    normalizedTokenSwapOrOverlap: number // The number of search tokens that are out-of-order or overlap with another token when they are matched against the haystack tokens ([0, 1], where 0 is no tokens are swapped or overlapped, and 1 is all tokens are swapped or overlapped)\n    normalizedPriorityType: 1 | 0 // Is this a priority type? 0 if true\n}\n\nconst weights = {\n    match: 5,\n    position: 5,\n    priority: 1.6,\n    population: 2,\n    incompleteMatches: 1,\n    swapOverlap: 1,\n    priorityType: 0.4,\n}\n\nconst sumOfWeights = Object.values(weights).reduce((total, value) => total + value, 0)\nconst normalizedWeights = Object.fromEntries(Object.entries(weights).map(([key, value]) => [key, value / sumOfWeights]))\n\nfunction combinedScore(result: Result): number {\n    return (result.normalizedMatchScore * normalizedWeights.match)\n        + (result.normalizedPositionScore * normalizedWeights.position)\n        + (result.normalizedPriority * normalizedWeights.priority)\n        + (result.normalizedPopulationRank * normalizedWeights.population)\n        + (result.normalizedTokensWithIncompleteMatch * normalizedWeights.incompleteMatches)\n        + (result.normalizedTokenSwapOrOverlap * normalizedWeights.swapOverlap)\n        + (result.normalizedPriorityType * normalizedWeights.priorityType)\n}\n\nfunction compareSearchResults(a: Result, b: Result): number {\n    return combinedScore(a) - combinedScore(b)\n}\n\nfunction tokenize(pattern: string): string[] {\n    const matchNoOverflow = /^ *([^ ]{1,31})(.*)$/.exec(pattern)\n    if (matchNoOverflow !== null) {\n        const [, token, rest] = matchNoOverflow\n        return [token, ...tokenize(rest)]\n    }\n\n    return []\n}\n\nexport interface SearchParams {\n    unnormalizedPattern: string\n    maxResults: number\n    showHistoricalCDs: boolean\n    prioritizeTypeIndex?: number\n}\n\nfunction search(searchIndex: NormalizedSearchIndex, { unnormalizedPattern, maxResults, showHistoricalCDs, prioritizeTypeIndex }: SearchParams): SearchResult[] {\n    const start = performance.now()\n\n    const pattern = normalize(unnormalizedPattern)\n\n    if (pattern === '') {\n        return []\n    }\n\n    let longestPatternToken = 0\n    const patternTokens = tokenize(pattern).map((token) => {\n        longestPatternToken = Math.max(longestPatternToken, token.length)\n        return toNeedle(token)\n    })\n\n    const results: Result[] = []\n\n    const maxErrors = 2\n    const maxMatchScore = patternTokens.length * (maxErrors + 1)\n    const maxPositionScore = patternTokens.length * Math.max(patternTokens.length, searchIndex.lengthOfLongestToken)\n\n    const bitapBuffers = Array.from({ length: maxErrors + 1 }, () => new Uint32Array(longestPatternToken + maxErrors + 1))\n\n    bitapPerformance.numBitapSignatureChecks = 0\n    bitapPerformance.numBitapSignatureSkips = 0\n\n    const patternSignature = toSignature(pattern)\n\n    let entriesPatternSkips = 0\n    let entriesPatternChecks = 0\n\n    entries: for (const [populationRank, entry] of searchIndex.entries.entries()) {\n        if (!showHistoricalCDs && isHistoricalCD(entry.typeIndex)) {\n            continue\n        }\n\n        entriesPatternChecks++\n        if (bitCount(patternSignature ^ (patternSignature & entry.signature)) > maxErrors) {\n            // This element doesn't have the correct letters to match this pattern\n            entriesPatternSkips++\n            continue\n        }\n\n        const normalizedPopulationRank = (populationRank / searchIndex.entries.length)\n\n        // If this entry wouldn't make it into the results even with a perfect match because of priority or population, continue\n        if (results.length === maxResults && compareSearchResults({\n            entry,\n            normalizedMatchScore: 0,\n            normalizedPositionScore: 0,\n            normalizedPriority: entry.priority / searchIndex.maxPriority,\n            normalizedPopulationRank,\n            normalizedTokensWithIncompleteMatch: 0,\n            normalizedTokenSwapOrOverlap: 0,\n            normalizedPriorityType: entry.typeIndex === prioritizeTypeIndex ? 0 : 1,\n        }, results[results.length - 1]) > 0) {\n            continue\n        }\n\n        let matchScore = 0\n        let positionScore = 0\n        let incompleteMatches = 0\n\n        let prevEntryTokenIndex = -1\n        let numSwapsOverlaps = 0\n\n        for (const [patternTokenIndex, needle] of patternTokens.entries()) {\n            let tokenMatchScore = maxErrors + 1\n            let tokenPositionScore = Math.max(patternTokens.length, searchIndex.lengthOfLongestToken)\n            let tokenIncompleteMatch = true\n            let tokenEntryTokenIndex: undefined | number\n\n            for (const [entryTokenIndex, entryToken] of entry.tokens.entries()) {\n                const searchResult = bitap(entryToken, needle, maxErrors, bitapBuffers)\n                const positionResult = Math.abs(patternTokenIndex - entryTokenIndex)\n                const incompleteMatchResult = Math.abs(entryToken.haystack.length - needle.length) - searchResult !== 0\n                if (searchResult < tokenMatchScore || (searchResult <= tokenMatchScore && positionResult < tokenPositionScore) || (searchResult <= tokenMatchScore && positionResult <= tokenPositionScore && incompleteMatchResult < tokenIncompleteMatch)) {\n                    tokenMatchScore = searchResult\n                    tokenPositionScore = positionResult\n                    tokenIncompleteMatch = incompleteMatchResult\n                    tokenEntryTokenIndex = entryTokenIndex\n                }\n            }\n\n            matchScore += tokenMatchScore\n            positionScore += tokenPositionScore\n            incompleteMatches += tokenIncompleteMatch ? 1 : 0\n            if (tokenEntryTokenIndex !== undefined) {\n                numSwapsOverlaps += prevEntryTokenIndex >= tokenEntryTokenIndex ? 1 : 0\n                prevEntryTokenIndex = tokenEntryTokenIndex\n            }\n\n            // If our match score is so high that we would not make it into the results, we can move on to the next entry\n            if (results.length === maxResults && compareSearchResults({\n                entry,\n                normalizedMatchScore: matchScore / maxMatchScore,\n                normalizedPositionScore: positionScore / maxPositionScore,\n                normalizedPriority: entry.priority / searchIndex.maxPriority,\n                normalizedPopulationRank,\n                normalizedTokensWithIncompleteMatch: incompleteMatches / patternTokens.length,\n                normalizedTokenSwapOrOverlap: numSwapsOverlaps / patternTokens.length,\n                normalizedPriorityType: entry.typeIndex === prioritizeTypeIndex ? 0 : 1,\n            }, results[results.length - 1]) > 0) {\n                continue entries\n            }\n        }\n\n        if (matchScore >= patternTokens.length * (maxErrors + 1)) {\n            // No match\n            continue\n        }\n\n        const result: Result = {\n            entry,\n            normalizedMatchScore: matchScore / maxMatchScore,\n            normalizedPositionScore: positionScore / maxPositionScore,\n            normalizedPriority: entry.priority / searchIndex.maxPriority,\n            normalizedPopulationRank,\n            normalizedTokensWithIncompleteMatch: incompleteMatches / patternTokens.length,\n            normalizedTokenSwapOrOverlap: numSwapsOverlaps / patternTokens.length,\n            normalizedPriorityType: entry.typeIndex === prioritizeTypeIndex ? 0 : 1,\n        }\n\n        let spliceIndex: number | undefined\n        for (let resultsIndex = Math.min(results.length, maxResults); resultsIndex >= 0; resultsIndex--) {\n            if (results.length <= resultsIndex || compareSearchResults(result, results[resultsIndex]) < 0) {\n                spliceIndex = resultsIndex\n            }\n            else {\n                break\n            }\n        }\n        if (spliceIndex !== undefined) {\n            results.splice(spliceIndex, 0, result)\n        }\n        if (results.length > maxResults) {\n            results.pop()\n        }\n    }\n\n    debug(bitapPerformance)\n    debug({ total: entriesPatternChecks, skips: entriesPatternSkips })\n\n    debug(results.map(result => ({\n        ...result,\n        combinedScore: combinedScore(result),\n    })))\n\n    debugPerformance(`Took ${performance.now() - start} ms to execute search`)\n\n    return results.map(result => result.entry)\n}\n\n// Potentially cached\nexport async function createIndex(cacheKey: string | undefined): Promise<(params: SearchParams) => SearchResult[]> {\n    let index: NormalizedSearchIndex | undefined\n    try {\n        if (cacheKey === undefined) {\n            throw new Error('No cache key specified')\n        }\n\n        let checkpoint = performance.now()\n\n        const db = await idb.openDB('SearchCache', 1, {\n            upgrade(database) {\n                database.createObjectStore('indexes')\n            },\n        })\n\n        const store = db.transaction('indexes', 'readonly').objectStore('indexes')\n\n        debugPerformance(`Took ${performance.now() - checkpoint}ms to open database`)\n        checkpoint = performance.now()\n\n        index = (await store.get(cacheKey)) as NormalizedSearchIndex | undefined\n\n        debugPerformance(`Took ${performance.now() - checkpoint}ms to get index from cache`)\n        checkpoint = performance.now()\n\n        if (index === undefined) {\n            debugPerformance('Cache miss')\n            index = await createIndexNoCache()\n\n            void (async () => {\n                const writeStore = db.transaction('indexes', 'readwrite').objectStore('indexes')\n                const keys = await writeStore.getAllKeys()\n                await Promise.all(keys.map(k => writeStore.delete(k)))\n                await writeStore.put(index, cacheKey)\n            })()\n        }\n        else {\n            debugPerformance('Cache hit')\n        }\n    }\n    catch (error) {\n        // This is going to fail during unit testing since we don't mock stuff\n        console.warn('Getting cached search index failed', error)\n        index = await createIndexNoCache()\n    }\n    return params => search(index, params)\n}\n\nasync function createIndexNoCache(): Promise<NormalizedSearchIndex> {\n    const rawIndex = await loadProtobuf('/index/pages_all.gz', 'SearchIndex')\n    return processRawSearchIndex(rawIndex)\n}\n\nfunction processRawSearchIndex(searchIndex: { elements: string[], metadata: ISearchIndexMetadata[] }): NormalizedSearchIndex {\n    const start = performance.now()\n    let lengthOfLongestToken = 0\n    let maxPriority = 0\n    let mostTokens = 0\n    const priorities = searchIndex.metadata.map(({ type }) => type_to_priority[type!])\n    const haystackCache = new DefaultMap<string, Haystack>((token) => {\n        if (token.length > lengthOfLongestToken) {\n            lengthOfLongestToken = token.length\n        }\n        return toHaystack(token)\n    })\n    const entries = searchIndex.elements.map((longname, index) => {\n        const normalizedLongname = normalize(longname)\n        const entryTokens = tokenize(normalizedLongname)\n        const tokens = entryTokens.map(token => haystackCache.get(token))\n        if (priorities[index] > maxPriority) {\n            maxPriority = priorities[index]\n        }\n        if (tokens.length > mostTokens) {\n            mostTokens = tokens.length\n        }\n        return {\n            longname,\n            tokens,\n            priority: priorities[index],\n            signature: toSignature(normalizedLongname),\n            typeIndex: searchIndex.metadata[index].type!,\n        }\n    })\n    debugPerformance(`Took ${performance.now() - start}ms to process search index`)\n    return { entries, lengthOfLongestToken, maxPriority, mostTokens }\n}\n\nexport async function getIndexCacheKey(): Promise<string | undefined> {\n    try {\n        const start = performance.now()\n        // location is sometimes a worker\n        const resources = ['/scripts/index.js', '/index/pages_all.gz', location.href]\n        const etags = await Promise.all(resources.map(async (resource) => {\n            const response = await fetch(resource, { method: 'HEAD' })\n            if (!response.ok) {\n                throw new Error(`${resource} is not OK`)\n            }\n            const etag = response.headers.get('etag')\n            if (etag === null) {\n                throw new Error(`${resource} does not have etag`)\n            }\n            return etag\n        }))\n\n        debugPerformance(`Took ${performance.now() - start} to get search cache key`)\n        return etags.join(',')\n    }\n    catch (error) {\n        console.warn('Getting search cache key failed', error)\n        return undefined\n    }\n}\n","const value: number[] = [\n    0,\n    0,\n    1,\n    1,\n    2,\n    2,\n    1,\n    1,\n    0,\n    3,\n    3,\n    3,\n    3,\n    3,\n    3,\n    4,\n    4,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    5,\n    4,\n    4,\n    4,\n    5,\n    6,\n    6,\n    6,\n    6,\n    6,\n    6,\n    7,\n    7,\n    7,\n    7,\n    7,\n    7,\n    7,\n    7\n]\nexport default value","import type_ordering_idx from '../data/type_ordering_idx'\nimport { StatName } from '../page_template/statistic-tree'\n\nimport { PageDescriptor } from './PageDescriptor'\n\nconst typesInOrder = Object.fromEntries(Object.entries(type_ordering_idx).map(([k, v]) => [v, k]))\n\nfunction shardBytes(longname: string): [string, string] {\n    // as bytes, in utf-8\n    const bytes = new TextEncoder().encode(longname)\n    const hash = new Uint32Array([0])\n    for (const byte of bytes) {\n        hash[0] = (hash[0] * 31 + byte) & 0xffffffff\n    }\n    // last 4 hex digits\n    let string = ''\n    for (let i = 0; i < 4; i++) {\n        string += (hash[0] & 0xf).toString(16)\n        hash[0] = hash[0] >> 4\n    }\n    // get first two and last two\n    return [\n        string.slice(0, 2),\n        string.slice(2, 3),\n    ]\n}\n\nfunction shardedFolderName(longname: string): string {\n    const sanitizedName = sanitize(longname)\n    const [a, b] = shardBytes(sanitizedName)\n    return `${a}/${b}`\n}\n\nexport function shardedName(longname: string): string {\n    const sanitizedName = sanitize(longname)\n    return `${shardedFolderName(longname)}/${sanitizedName}`\n}\n\nexport function shapeLink(longname: string): string {\n    return `/shape/${encodeURIComponent(shardedName(longname))}.gz`\n}\n\nexport function dataLink(longname: string): string {\n    return `/data/${encodeURIComponent(shardedName(longname))}.gz`\n}\n\nexport function symlinksLink(longname: string): string {\n    return `/data/${shardedFolderName(longname)}.symlinks.gz`\n}\n\nexport function indexLink(universe: string, typ: string): string {\n    return `/index/${universe}/${encodeURIComponent(sanitize(typ, false))}.gz`\n}\n\nexport function orderingLink(universe: string, type: string, idx: number): string {\n    return `/order/${universe}/${encodeURIComponent(sanitize(type, false))}_${idx}.gz`\n}\n\nexport function orderingDataLink(universe: string, type: string, idx: number): string {\n    return `/order/${universe}/${encodeURIComponent(sanitize(type, false))}_${idx}_data.gz`\n}\n\nexport function consolidatedShapeLink(typ: string): string {\n    return `/consolidated/shapes__${encodeURIComponent(sanitize(typ))}.gz`\n}\n\nexport function consolidatedStatsLink(typ: string): string {\n    return `/consolidated/stats__${encodeURIComponent(sanitize(typ))}.gz`\n}\n\nexport function searchIconLink(typeIdx: number): string {\n    return `/icons/search_icons/${typesInOrder[typeIdx]}.png`\n}\n\nexport function centroidsPath(universe: string, typ: string): string {\n    return `/centroids/${encodeURIComponent(universe)}_${encodeURIComponent(sanitize(typ))}.gz`\n}\n\nexport function statisticDescriptor(props: {\n    universe: string | undefined\n    statname: StatName\n    articleType: string\n    start: number\n    amount: number | 'All'\n    order: 'ascending' | 'descending'\n    highlight?: string\n}): PageDescriptor & { kind: 'statistic' } {\n    let start = props.start\n    // make start % amount == 0\n    if (props.amount !== 'All') {\n        start = start - 1\n        start = start - (start % props.amount)\n        start = start + 1\n    }\n    return {\n        kind: 'statistic',\n        statname: props.statname,\n        article_type: props.articleType,\n        start,\n        amount: props.amount,\n        order: props.order,\n        highlight: props.highlight,\n        universe: props.universe,\n    }\n}\n\nexport function sanitize(longname: string, spaces_around_slash = true): string {\n    let x = longname\n    if (spaces_around_slash) {\n        x = x.replaceAll('/', ' slash ')\n    }\n    else {\n        x = x.replaceAll('/', 'slash')\n    }\n    x = x.replaceAll('%', '%25')\n    return x\n}\n\nexport function universePath(universe: string): string {\n    return `/icons/flags/${encodeURIComponent(universe)}.png`\n}\n","export interface ReadonlyDefaultMap<K, V> extends ReadonlyMap<K, V> {\n    get: (key: K) => V\n}\n\nexport class DefaultMap<K, V> extends Map<K, V> implements ReadonlyDefaultMap<K, V> {\n    override get(key: K): V {\n        let result = super.get(key)\n        if (result === undefined) {\n            result = this.makeDefault(key)\n            this.set(key, result)\n        }\n        return result\n    }\n\n    constructor(private readonly makeDefault: (key: K) => V) {\n        super()\n    }\n}\n","/**\n * Algorithm for fuzzy string matching and associated utilities.\n *\n * This a modified bitap algorithm that's optimized for matching short strings to short strings.\n * It uses a signature that's based on the count of letters in the needle and haystack to quickly skip combinations that can't match.\n */\n\nimport { assert } from './defensive'\n\nexport interface Needle {\n    alphabet: Uint32Array\n    length: number\n    signature: number\n}\n\nexport function bitapAlphabet(token: string): Uint32Array {\n    assert(token.length <= 31, `Max bitap token length is 31`)\n    const alphabet = new Uint32Array(65535).fill(0)\n    for (let i = 0; i < token.length; i++) {\n        const char = token.charCodeAt(i)\n        alphabet[char] = alphabet[char] | (1 << i)\n    }\n    return alphabet\n}\n\nexport function toNeedle(token: string): Needle {\n    return { alphabet: bitapAlphabet(token), length: token.length, signature: toSignature(token) }\n}\n\nexport interface Haystack {\n    haystack: string\n    signature: number\n}\n\nexport function toHaystack(token: string): Haystack {\n    return {\n        haystack: token,\n        signature: toSignature(token),\n    }\n}\n\nexport function toSignature(str: string): number {\n    const alphabetStart = 'a'.charCodeAt(0)\n    const alphabetEnd = 'z'.charCodeAt(0)\n    // 0 < alphabetEnd - alphabetStart < 26   because of javascript integer size\n    let result = 0\n    for (let i = 0; i < str.length; i++) {\n        const charCode = str.charCodeAt(i)\n        if (charCode >= alphabetStart && charCode <= alphabetEnd) {\n            const firstOccurence = (1 << ((charCode - alphabetStart) * 2))\n            if ((result & firstOccurence) !== 0) {\n                result |= (firstOccurence << 1) // second occurence\n            }\n            else {\n                result |= firstOccurence\n            }\n        }\n    }\n    return result\n}\n\nexport const bitapPerformance = {\n    numBitapSignatureChecks: 0,\n    numBitapSignatureSkips: 0,\n}\n\n/**\n * Finds the minimum number of edits between `haystack` and `needle` (assuming they have the same start position)\n *\n * Returns [0, maxErrors + 1], where maxErrors + 1 means a match was not found with lte maxErrors errors\n *\n * Takes scratch buffers, which must be an array of at least length maxErrors + 1 length, filled with Uint32Arrays of at least (needle.length + maxErrors + 1) length\n *\n */\nexport function bitap(haystack: Haystack, needle: Needle, maxErrors: number, scratchBuffers: Uint32Array[]): number {\n    let bestMatch = maxErrors + 1\n\n    if (maxErrors < 0) {\n        return bestMatch\n    }\n\n    bitapPerformance.numBitapSignatureChecks++\n    if (bitCount(needle.signature ^ (haystack.signature & needle.signature)) > maxErrors) {\n        bitapPerformance.numBitapSignatureSkips++\n        return bestMatch // The letters in the haystack and needle are too different to possibly match\n    }\n\n    for (let errors = 0; errors <= maxErrors; errors++) {\n        scratchBuffers[errors].fill(0)\n        scratchBuffers[errors][0] = (1 << errors) - 1\n    }\n\n    const matchMask = 1 << (needle.length - 1)\n\n    for (let j = 1; j <= (needle.length + maxErrors); j++) {\n        let charMatch: number\n        if (j - 1 < haystack.haystack.length) {\n            charMatch = needle.alphabet[haystack.haystack.charCodeAt(j - 1)]\n        }\n        else {\n            charMatch = 0\n        }\n\n        for (let errors = 0; errors <= maxErrors; errors++) {\n            if (errors === 0) {\n                scratchBuffers[0][j] = ((scratchBuffers[0][j - 1] << 1) | 1) & charMatch\n            }\n            else {\n                scratchBuffers[errors][j] = (((scratchBuffers[errors][j - 1] << 1) | 1) & charMatch) | (((scratchBuffers[errors - 1][j - 1] | scratchBuffers[errors - 1][j]) << 1) | 1) | scratchBuffers[errors - 1][j - 1]\n            }\n\n            if ((scratchBuffers[errors][j] & matchMask) !== 0) {\n                bestMatch = Math.min(bestMatch, Math.max(Math.abs(j - needle.length), errors))\n                maxErrors = Math.min(maxErrors, errors)\n                if (bestMatch === 0) {\n                    return bestMatch // We've found the best match we possibly can\n                }\n            }\n        }\n    }\n    return bestMatch\n}\n\nexport function bitCount(x: number): number {\n    return bitCount32(x) + bitCount32(Math.floor(x / 0x1_0000_0000))\n}\n\n// https://stackoverflow.com/a/109025\nfunction bitCount32(i: number): number {\n    i = i - ((i >> 1) & 0x55555555) // add pairs of bits\n    i = (i & 0x33333333) + ((i >> 2) & 0x33333333) // quads\n    i = (i + (i >> 4)) & 0x0F0F0F0F // groups of 8\n    i *= 0x01010101 // horizontal sum of bytes\n    return i >> 24\n}\n","import type_ordering_idx from '../data/type_ordering_idx'\n\nconst historicalCongressionals = Object.keys(type_ordering_idx).filter(\n    key => key.startsWith('Congressional District ('),\n)\nconst historicalCongressionalsIdx = historicalCongressionals.map(\n    key => type_ordering_idx[key],\n)\n\nexport function isHistoricalCD(typeOrTypeIndex: number | string): boolean {\n    if (typeof typeOrTypeIndex === 'string') {\n        return historicalCongressionals.includes(typeOrTypeIndex)\n    }\n    return historicalCongressionalsIdx.includes(typeOrTypeIndex)\n}\n","import { gunzipSync } from 'zlib'\n\nimport data_links from './data/data_links'\nimport order_links from './data/order_links'\nimport statistic_path_list from './data/statistic_path_list'\nimport { indexLink, orderingDataLink, orderingLink } from './navigation/links'\nimport { debugPerformance } from './search'\nimport { assert } from './utils/defensive'\nimport {\n    Article, ConsolidatedShapes, CountsByArticleUniverseAndType, DataLists,\n    Feature, IDataList, IOrderList, OrderList,\n    OrderLists,\n    QuizFullData,\n    QuizQuestionTronche,\n    SearchIndex,\n    ArticleOrderingList,\n    Symlinks,\n    PointSeries,\n} from './utils/protos'\nimport { NormalizeProto } from './utils/types'\n\n// from https://stackoverflow.com/a/4117299/1549476\n\n// Load JSON text from server hosted file and return JSON parsed object\nexport async function loadJSON(filePath: string): Promise<unknown> {\n    const response = await fetch(filePath, { headers: { 'Content-Type': 'application/json' } })\n    if (response.status < 200 || response.status > 299) {\n        throw new Error(`Expected response status 2xx for ${filePath}, got ${response.status}: ${response.statusText}`)\n    }\n    return response.json()\n}\n\n// Load a protobuf file from the server\nexport async function loadProtobuf(filePath: string, name: 'Article', errorOnMissing: boolean): Promise<Article | undefined>\nexport async function loadProtobuf(filePath: string, name: 'Feature', errorOnMissing: boolean): Promise<Feature>\nexport async function loadProtobuf(filePath: string, name: 'ArticleOrderingList'): Promise<ArticleOrderingList>\nexport async function loadProtobuf(filePath: string, name: 'OrderLists'): Promise<OrderLists>\nexport async function loadProtobuf(filePath: string, name: 'DataLists'): Promise<DataLists>\nexport async function loadProtobuf(filePath: string, name: 'ConsolidatedShapes'): Promise<ConsolidatedShapes>\nexport async function loadProtobuf(filePath: string, name: 'SearchIndex'): Promise<SearchIndex>\nexport async function loadProtobuf(filePath: string, name: 'QuizQuestionTronche'): Promise<QuizQuestionTronche>\nexport async function loadProtobuf(filePath: string, name: 'QuizFullData'): Promise<QuizFullData>\nexport async function loadProtobuf(filePath: string, name: 'CountsByArticleUniverseAndType'): Promise<CountsByArticleUniverseAndType>\nexport async function loadProtobuf(filePath: string, name: 'Symlinks'): Promise<Symlinks>\nexport async function loadProtobuf(filePath: string, name: 'PointSeries'): Promise<PointSeries>\nexport async function loadProtobuf(filePath: string, name: string, errorOnMissing: boolean = true): Promise<Article | Feature | ArticleOrderingList | OrderLists | DataLists | ConsolidatedShapes | SearchIndex | QuizQuestionTronche | QuizFullData | CountsByArticleUniverseAndType | Symlinks | PointSeries | undefined> {\n    let perfCheckpoint = performance.now()\n\n    const response = await fetch(filePath)\n    if (response.status < 200 || response.status > 299) {\n        if (!errorOnMissing) {\n            return undefined\n        }\n        throw new Error(`Expected response status 2xx for ${filePath}, got ${response.status}: ${response.statusText}`)\n    }\n\n    const compressedBuffer = await response.arrayBuffer()\n\n    if (name === 'SearchIndex') {\n        debugPerformance(`Took ${performance.now() - perfCheckpoint}ms networking to load search index`)\n    }\n    perfCheckpoint = performance.now()\n\n    const buffer = gunzipSync(Buffer.from(compressedBuffer))\n    const arr = new Uint8Array(buffer)\n\n    if (name === 'SearchIndex') {\n        debugPerformance(`Took ${performance.now() - perfCheckpoint}ms to decompress search index`)\n    }\n    perfCheckpoint = performance.now()\n\n    if (name === 'Article') {\n        return Article.decode(arr)\n    }\n    else if (name === 'Feature') {\n        return Feature.decode(arr)\n    }\n    else if (name === 'ArticleOrderingList') {\n        return ArticleOrderingList.decode(arr)\n    }\n    else if (name === 'OrderLists') {\n        return OrderLists.decode(arr)\n    }\n    else if (name === 'DataLists') {\n        return DataLists.decode(arr)\n    }\n    else if (name === 'ConsolidatedShapes') {\n        return ConsolidatedShapes.decode(arr)\n    }\n    else if (name === 'SearchIndex') {\n        const result = SearchIndex.decode(arr)\n        debugPerformance(`Took ${performance.now() - perfCheckpoint}ms to decode search index`)\n        return result\n    }\n    else if (name === 'QuizQuestionTronche') {\n        return QuizQuestionTronche.decode(arr)\n    }\n    else if (name === 'QuizFullData') {\n        return QuizFullData.decode(arr)\n    }\n    else if (name === 'CountsByArticleUniverseAndType') {\n        return CountsByArticleUniverseAndType.decode(arr)\n    }\n    else if (name === 'Symlinks') {\n        return Symlinks.decode(arr)\n    }\n    else if (name === 'PointSeries') {\n        return PointSeries.decode(arr)\n    }\n    else {\n        throw new Error('protobuf type not recognized (see load_json.ts)')\n    }\n}\n\nfunction pullKey(arr: number[], key: string): number {\n    const idx = statistic_path_list.indexOf(key as ElementOf<typeof statistic_path_list>)\n    if (idx === -1) {\n        throw new Error(`statistic path not found: ${key}`)\n    }\n    let current = 0\n    for (let i = 0; i < arr.length; i++) {\n        current += arr[i]\n        if (idx < current) {\n            return i\n        }\n    }\n    throw new Error('index not found')\n}\n\nexport async function loadOrderingProtobuf(universe: string, statpath: string, type: string, isData: true): Promise<IDataList>\nexport async function loadOrderingProtobuf(universe: string, statpath: string, type: string, isData: boolean): Promise<IOrderList>\nexport async function loadOrderingProtobuf(universe: string, statpath: string, type: string, isData: boolean): Promise<IDataList | IOrderList> {\n    const links = isData ? data_links : order_links\n    const key = `${universe}__${type}`\n    const idx = key in links ? pullKey(links[key], statpath) : 0\n    const orderLink = isData ? orderingDataLink(universe, type, idx) : orderingLink(universe, type, idx)\n    if (isData) {\n        const dataLists = await loadProtobuf(orderLink, 'DataLists')\n        const index = dataLists.statnames.indexOf(statpath)\n        return dataLists.dataLists[index]\n    }\n    else {\n        const orderLists = await loadProtobuf(orderLink, 'OrderLists')\n        const index = orderLists.statnames.indexOf(statpath)\n        return orderLists.orderLists[index]\n    }\n}\n\nexport interface ArticleOrderingListInternal {\n    longnames: string[]\n    typeIndices: number[]\n}\n\nexport async function loadOrdering(universe: string, statpath: string, type: string): Promise<ArticleOrderingListInternal> {\n    const idxLink = indexLink(universe, type)\n    const dataPromise = loadProtobuf(idxLink, 'ArticleOrderingList')\n    const orderingPromise = loadOrderingProtobuf(universe, statpath, type, false)\n    const [data, ordering] = await Promise.all([dataPromise, orderingPromise])\n    const namesInOrder = (ordering as OrderList).orderIdxs.map((i: number) => data.longnames[i])\n    const typesInOrder = (ordering as OrderList).orderIdxs.map((i: number) => data.types[i])\n    return { longnames: namesInOrder, typeIndices: typesInOrder }\n}\n\nexport async function loadDataInIndexOrder(\n    universe: string, statpath: string, type: string,\n): Promise<number[]> {\n    const dataPromise = loadOrderingProtobuf(universe, statpath, type, true)\n    const orderingPromise = loadOrderingProtobuf(universe, statpath, type, false)\n    const [data, ordering] = await Promise.all([dataPromise, orderingPromise])\n    const dataList = data.value\n    const orderIdxs = ordering.orderIdxs\n    assert(Array.isArray(dataList), 'Data list must be an array')\n    assert(Array.isArray(orderIdxs), 'Order indices must be an array')\n    // unsort data list, according to order indices\n    const unsortedData = new Array<number>(orderIdxs.length)\n    for (let i = 0; i < orderIdxs.length; i++) {\n        const idx = orderIdxs[i]\n        unsortedData[idx] = dataList[i]\n    }\n    return unsortedData\n}\n\nexport async function loadStatisticsPage(\n    statUniverse: string, statpath: string, articleType: string,\n): Promise<[NormalizeProto<IDataList>, string[]]> {\n    const data = loadOrderingProtobuf(statUniverse, statpath, articleType, true).then(result => result as NormalizeProto<IDataList>)\n    const articleNames = loadOrdering(statUniverse, statpath, articleType).then(result => result.longnames)\n    return [await data, await articleNames]\n}\n","import { createIndex, debugPerformance, SearchParams } from './search'\n\ndebugPerformance(`Search worker starting at timestamp ${Date.now()}`)\n\n// @ts-expect-error -- Web worker\nconst cacheKey: string | undefined = name\nconst searchIndex = createIndex(cacheKey)\n\nonmessage = async (message: MessageEvent<SearchParams>) => {\n    const search = await searchIndex // This maintains message ordering https://stackoverflow.com/questions/63427239/order-of-resolution-for-multiple-awaits-on-one-promise#comment138162017_63427370\n    postMessage(search(message.data))\n}\n","__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n        if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n            Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n        }\n    }\n};","__webpack_require__.f = {};\n// This file contains only the entry chunk.\n// The chunk loading function for additional chunks\n__webpack_require__.e = (chunkId) => {\n\treturn Promise.all(\n\t\tObject.keys(__webpack_require__.f).reduce((promises, key) => {\n\t\t\t__webpack_require__.f[key](chunkId, promises);\n\t\t\treturn promises;\n\t\t}, [])\n\t);\n};","// This function allow to reference chunks\n__webpack_require__.u = (chunkId) => {\n  // return url for filenames not based on template\n  \n  // return url for filenames based on template\n  return \"\" + chunkId + \".js\"\n}","__webpack_require__.g = (() => {\n\tif (typeof globalThis === 'object') return globalThis;\n\ttry {\n\t\treturn this || new Function('return this')();\n\t} catch (e) {\n\t\tif (typeof window === 'object') return window;\n\t}\n})();","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","var deferred = [];\n__webpack_require__.O = (result, chunkIds, fn, priority) => {\n\tif (chunkIds) {\n\t\tpriority = priority || 0;\n\t\tfor (var i = deferred.length; i > 0 && deferred[i - 1][2] > priority; i--)\n\t\t\tdeferred[i] = deferred[i - 1];\n\t\tdeferred[i] = [chunkIds, fn, priority];\n\t\treturn;\n\t}\n\tvar notFulfilled = Infinity;\n\tfor (var i = 0; i < deferred.length; i++) {\n\t\tvar [chunkIds, fn, priority] = deferred[i];\n\t\tvar fulfilled = true;\n\t\tfor (var j = 0; j < chunkIds.length; j++) {\n\t\t\tif (\n\t\t\t\t(priority & (1 === 0) || notFulfilled >= priority) &&\n\t\t\t\tObject.keys(__webpack_require__.O).every((key) => (__webpack_require__.O[key](chunkIds[j])))\n\t\t\t) {\n\t\t\t\tchunkIds.splice(j--, 1);\n\t\t\t} else {\n\t\t\t\tfulfilled = false;\n\t\t\t\tif (priority < notFulfilled) notFulfilled = priority;\n\t\t\t}\n\t\t}\n\t\tif (fulfilled) {\n\t\t\tdeferred.splice(i--, 1);\n\t\t\tvar r = fn();\n\t\t\tif (r !== undefined) result = r;\n\t\t}\n\t}\n\treturn result;\n};\n","__webpack_require__.rv = () => (\"1.3.15\")","var next = __webpack_require__.x\n__webpack_require__.x = () => {\n  return Promise.all([\"90\",\"921\",\"427\"].map(__webpack_require__.e, __webpack_require__)).then(next);\n}","var scriptUrl;\n\nif (__webpack_require__.g.importScripts) scriptUrl = __webpack_require__.g.location + \"\";\nvar document = __webpack_require__.g.document;\nif (!scriptUrl && document) {\n  // Technically we could use `document.currentScript instanceof window.HTMLScriptElement`,\n  // but an attacker could try to inject `<script>HTMLScriptElement = HTMLImageElement</script>`\n  // and use `<img name=\"currentScript\" src=\"https://attacker.controlled.server/\"></img>`\n  if (document.currentScript && document.currentScript.tagName.toUpperCase() === 'SCRIPT') scriptUrl = document.currentScript.src;\n  if (!scriptUrl) {\n    var scripts = document.getElementsByTagName(\"script\");\n    if (scripts.length) {\n      var i = scripts.length - 1;\n      while (i > -1 && (!scriptUrl || !/^http(s?):/.test(scriptUrl))) scriptUrl = scripts[i--].src;\n    }\n  }\n}\n\n// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration\",\n// or pass an empty string (\"\") and set the __webpack_public_path__ variable from your code to use your own logic.',\nif (!scriptUrl) throw new Error(\"Automatic publicPath is not supported in this browser\");\nscriptUrl = scriptUrl.replace(/^blob:/, \"\").replace(/#.*$/, \"\").replace(/\\?.*$/, \"\").replace(/\\/[^\\/]+$/, \"/\");\n__webpack_require__.p = scriptUrl","var installedChunks = {\"308\": 1,};\n// importScripts chunk loading\nvar installChunk = (data) => {\n    var [chunkIds, moreModules, runtime] = data;\n    for (var moduleId in moreModules) {\n        if (__webpack_require__.o(moreModules, moduleId)) {\n            __webpack_require__.m[moduleId] = moreModules[moduleId];\n        }\n    }\n    if (runtime) runtime(__webpack_require__);\n    while (chunkIds.length) installedChunks[chunkIds.pop()] = 1;\n    parentChunkLoadingFunction(data);\n};\n\n__webpack_require__.f.i = (chunkId, promises) => {\n    \n          // \"1\" is the signal for \"already loaded\n          if (!installedChunks[chunkId]) {\n            if (true) {\n              importScripts(__webpack_require__.p + __webpack_require__.u(chunkId));\n            }\n          }\n          \n};\n\nvar chunkLoadingGlobal = self[\"webpackChunkassets\"] = self[\"webpackChunkassets\"] || [];\nvar parentChunkLoadingFunction = chunkLoadingGlobal.push.bind(chunkLoadingGlobal);\nchunkLoadingGlobal.push = installChunk;","__webpack_require__.ruid = \"bundler=rspack@1.3.15\";\n"],"names":["cacheKey","Object","type_ordering_idx","k","v","DefaultMap","makeDefault","get","key","result","undefined","Map","toSignature","str","i","charCode","firstOccurence","bitapPerformance","bitCount","x","bitCount32","Math","historicalCongressionals","historicalCongressionalsIdx","debug","arg","debugPerformance","normalize","a","handlePunctuation","weights","sumOfWeights","total","value","normalizedWeights","combinedScore","tokenize","pattern","matchNoOverflow","_matchNoOverflow","createIndexNoCache","loadProtobuf","filePath","name","errorOnMissing","perfCheckpoint","response","compressedBuffer","arr","performance","fetch","Error","Uint8Array","gunzipSync","Buffer","Article","Feature","ArticleOrderingList","OrderLists","DataLists","ConsolidatedShapes","SearchIndex","QuizQuestionTronche","QuizFullData","CountsByArticleUniverseAndType","Symlinks","PointSeries","searchIndex","start","lengthOfLongestToken","maxPriority","mostTokens","priorities","haystackCache","entries","type_to_priority","type","token","longname","index","normalizedLongname","tokens","entryTokens","Date","checkpoint","db","store","error","idb","upgrade","database","writeStore","Promise","keys","console","params","search","param","unnormalizedPattern","maxResults","showHistoricalCDs","prioritizeTypeIndex","longestPatternToken","patternTokens","bitapAlphabet","assert","alphabet","Uint32Array","char","results","maxMatchScore","maxErrors","maxPositionScore","bitapBuffers","Array","patternSignature","entriesPatternSkips","entriesPatternChecks","_iteratorError","populationRank","entry","typeOrTypeIndex","normalizedPopulationRank","compareSearchResults","b","matchScore","positionScore","incompleteMatches","prevEntryTokenIndex","numSwapsOverlaps","_iteratorError1","patternTokenIndex","needle","tokenMatchScore","tokenPositionScore","tokenIncompleteMatch","tokenEntryTokenIndex","_iteratorError2","entryTokenIndex","entryToken","searchResult","bitap","haystack","scratchBuffers","bestMatch","errors","matchMask","j","charMatch","errors1","positionResult","incompleteMatchResult","spliceIndex","resultsIndex","onmessage","message","postMessage","e","globalThis","Function","window","importScripts","self"],"mappings":"oDAyQkCA,E,WCtMlC,MAnEwB,CACpB,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACA,EACH,C,gIC7DoBC,OAAO,WAAW,CAACA,OAAO,OAAO,CAACC,EAAAA,CAAiBA,EAAE,GAAG,CAAC,Y,m0BAAEC,EAAAA,CAAAA,CAAAA,EAAAA,C,MAAU,CAAPC,CAAAA,CAAAA,EAAAA,CAAWD,EAAE,A,48CCDzF,IAAME,EAAN,gB,wBAAMA,G,OAAAA,E,+EAAAA,EAUoBC,CAA0B,M,+BAV9CD,C,oEAAAA,G,+PAWL,K,6BAAA,M,qBAAA,K,MAXKA,KAAAA,E,GAAAA,iBAAAA,E,sBAAAA,E,uDAAAA,C,MAAAA,EAUoBC,WAAW,CAAXA,E,SAVpBD,E,wBAAAA,G,AAAAA,E,8BAAAA,E,+BAAAA,G,EAAAA,EAAAA,G,EAAAA,C,CACAE,IAAAA,M,MAAT,SAAaC,CAAM,EACf,IAAIC,EAAS,IAFRJ,EAAAA,SAAAA,EAEc,MAAN,IAAK,YAAKG,GAKvB,OAJeE,SAAXD,IACAA,EAAS,IAAI,CAAC,WAAW,CAACD,GAC1B,IAAI,CAAC,GAAG,CAACA,EAAKC,IAEXA,CACX,C,wKARSJ,E,aAAAA,C,IAAyBM,M,WCqC/B,SAASC,EAAYC,CAAW,EAKnC,IAAK,IADDJ,EAAS,EACJK,EAAI,EAAGA,EAAID,EAAI,MAAM,CAAEC,IAAK,CACjC,IAAMC,EAAWF,EAAI,UAAU,CAACC,GAChC,GAAIC,GANc,IAMeA,GALjB,IAK0C,CACtD,IAAMC,EAAkB,GAAOD,AAAAA,CAAAA,EAPjB,EAOwC,EAAK,CACtDN,CAAAA,CAAAA,EAASO,CAAa,GAAO,EAC9BP,GAAWO,GAAkB,EAG7BP,GAAUO,CAElB,CACJ,CACA,OAAOP,CACX,CAEO,IAAMQ,EAAmB,CAC5B,wBAAyB,EACzB,uBAAwB,CAC5B,EA2DO,SAASC,EAASC,CAAS,EAC9B,OAAOC,EAAWD,GAAKC,EAAWC,KAAK,KAAK,CAACF,EAAI,aACrD,CAGA,SAASC,EAAWN,CAAS,EAKzB,OAJAA,GAAUA,GAAK,EAAK,WAIbA,AADPA,CAAAA,EADKA,CADLA,CAAAA,EAAKA,AAAAA,CAAAA,AAAI,WAAJA,CAAa,EAAOA,CAAAA,GAAK,EAAK,UAAS,GAClCA,CAAAA,GAAK,GAAM,SAAS,EACzB,SAAS,GACF,EAChB,CCpIA,IAAMQ,EAA2BrB,OAAO,IAAI,CAACC,EAAAA,CAAiBA,EAAE,MAAM,CAClEM,SAAAA,CAAG,E,OAAIA,EAAI,UAAU,CAAC,2B,GAEpBe,EAA8BD,EAAyB,GAAG,CAC5Dd,SAAAA,CAAG,E,OAAIN,EAAAA,CAAiB,CAACM,EAAI,A,q3ELUjC,SAASgB,EAAMC,CAAY,EAK3B,CAIO,SAASC,EAAiBD,CAAY,EAK7C,CAEO,SAASE,EAAUC,CAAS,E,IAAEC,EAAAA,CAAAA,CAAAA,UAAAA,MAAAA,CAAAA,IAAAA,AAAAA,KAAAA,IAAAA,SAAAA,CAAAA,EAAAA,EAAAA,SAAAA,CAAAA,EAAAA,CAQjC,OALAD,EAAIA,AADJA,CAAAA,EAAIA,AADJA,CAAAA,EAAIA,EAAE,WAAW,EAAC,EACZ,SAAS,CAAC,MAAK,EACf,OAAO,CAAC,mBAAoB,IAC9BC,GAEAD,CAAAA,EAAIA,AADJA,CAAAA,EAAIA,EAAE,OAAO,CAAC,eAAgB,GAAE,EAC1B,UAAU,CAAC,IAAK,IAAG,EAEtBA,CACX,CA0BA,IAAME,EAAU,CACZ,MAAO,EACP,SAAU,EACV,SAAU,IACV,WAAY,EACZ,kBAAmB,EACnB,YAAa,EACb,aAAc,EAClB,EAEMC,EAAe9B,OAAO,MAAM,CAAC6B,GAAS,MAAM,CAAC,SAACE,CAAK,CAAEC,CAAK,E,OAAKD,EAAQC,C,EAAO,GAC9EC,EAAoBjC,OAAO,WAAW,CAACA,OAAO,OAAO,CAAC6B,GAAS,GAAG,CAAC,Y,mBAAkB,CAAhBtB,CAAAA,CAAAA,EAAAA,CAAsByB,AAAjBA,CAAAA,CAAAA,EAAAA,CAAyBF,EAAa,A,IAEtH,SAASI,EAAc1B,CAAc,EACjC,OAAQA,EAAO,oBAAoB,CAAGyB,EAAkB,KAAK,CACtDzB,EAAO,uBAAuB,CAAGyB,EAAkB,QAAQ,CAC3DzB,EAAO,kBAAkB,CAAGyB,EAAkB,QAAQ,CACtDzB,EAAO,wBAAwB,CAAGyB,EAAkB,UAAU,CAC9DzB,EAAO,mCAAmC,CAAGyB,EAAkB,iBAAiB,CAChFzB,EAAO,4BAA4B,CAAGyB,EAAkB,WAAW,CACnEzB,EAAO,sBAAsB,CAAGyB,EAAkB,YAAY,AACzE,CAMA,SAASE,EAASC,CAAe,EAC7B,IAAMC,EAAkB,uBAAuB,IAAI,CAACD,GACpD,GAAIC,AAAoB,OAApBA,EAA0B,CAC1B,I,EAAwBC,EAAAA,EAAAA,EAAAA,GACxB,MAAO,CADiBA,CAAAA,CAAAA,EAAAA,CACS,CAA1B,O,+CAAWH,EADMG,CAAAA,CAAAA,EAAAA,I,kSAE5B,CAEA,MAAO,EAAE,AACb,CAmNA,SAAeC,I,qEACM,O,EAAMC,AM7QpB,SAA4BC,CAAgB,CAAEC,CAAY,E,MAAEC,EAAAA,CAAAA,CAAAA,UAAAA,MAAAA,CAAAA,IAAAA,AAAAA,KAAAA,IAAAA,SAAAA,CAAAA,EAAAA,EAAAA,SAAAA,CAAAA,EAAAA,C,wBAC3DC,EAEEC,EAQAC,EAQAC,EA0BIvC,E,+pCA1CO,OAFboC,EAAiBI,YAAY,GAAG,GAEnB,C,EAAMC,MAAMR,G,QAC7B,GAAII,AADEA,CAAAA,EAAW,UACJ,MAAM,CAAG,KAAOA,EAAS,MAAM,CAAG,IAAK,CAChD,GAAI,CAACF,EACD,MAAO,C,EAAAlC,O,AAEX,OAAM,AAAIyC,MAAO,oCAAoDL,MAAAA,CAAjBJ,EAAS,UAA4BI,MAAAA,CAApBA,EAAS,MAAM,CAAC,MAAwB,OAApBA,EAAS,UAAU,EAChH,CAEyB,O,EAAMA,EAAS,WAAW,G,QAenD,GAfMC,EAAmB,SAErBJ,AAAS,gBAATA,GACAjB,EAAkB,QAA0C,OAAnCuB,YAAY,GAAG,GAAKJ,EAAe,uCAEhEA,EAAiBI,YAAY,GAAG,GAG1BD,EAAM,IAAII,WADDC,AAAAA,GAAAA,EAAAA,UAAAA,AAAAA,EAAWC,EAAO,IAAI,CAACP,KAGlCJ,AAAS,gBAATA,GACAjB,EAAkB,QAA0C,OAAnCuB,YAAY,GAAG,GAAKJ,EAAe,kCAEhEA,EAAiBI,YAAY,GAAG,GAE5BN,AAAS,YAATA,EACA,MAAO,C,EAAAY,EAAAA,EAAAA,CAAAA,MAAc,CAACP,G,CAErB,GAAIL,AAAS,YAATA,EACL,MAAO,C,EAAAa,EAAAA,EAAAA,CAAAA,MAAc,CAACR,G,CAErB,GAAIL,AAAS,wBAATA,EACL,MAAO,C,EAAAc,EAAAA,EAAAA,CAAAA,MAA0B,CAACT,G,MAEjC,GAAIL,AAAS,eAATA,EACL,MAAO,C,EAAAe,EAAAA,EAAAA,CAAAA,MAAiB,CAACV,G,MAExB,GAAIL,AAAS,cAATA,EACL,MAAO,C,EAAAgB,EAAAA,EAAAA,CAAAA,MAAgB,CAACX,G,MAEvB,GAAIL,AAAS,uBAATA,EACL,MAAO,C,EAAAiB,EAAAA,EAAAA,CAAAA,MAAyB,CAACZ,G,MAEhC,GAAIL,AAAS,gBAATA,EAGL,OAFMlC,EAASoD,EAAAA,EAAAA,CAAAA,MAAkB,CAACb,GAClCtB,EAAkB,QAA0C,OAAnCuB,YAAY,GAAG,GAAKJ,EAAe,8BACrD,C,EAAApC,E,MAEN,GAAIkC,AAAS,wBAATA,EACL,MAAO,C,EAAAmB,EAAAA,EAAAA,CAAAA,MAA0B,CAACd,G,MAEjC,GAAIL,AAAS,iBAATA,EACL,MAAO,C,EAAAoB,EAAAA,EAAAA,CAAAA,MAAmB,CAACf,G,MAE1B,GAAIL,AAAS,mCAATA,EACL,MAAO,C,EAAAqB,EAAAA,EAAAA,CAAAA,MAAqC,CAAChB,G,MAE5C,GAAIL,AAAS,aAATA,EACL,MAAO,C,EAAAsB,EAAAA,EAAAA,CAAAA,MAAe,CAACjB,G,MAEtB,GAAIL,AAAS,gBAATA,EACL,MAAO,C,EAAAuB,EAAAA,EAAAA,CAAAA,MAAkB,CAAClB,G,MAG1B,MAAM,AAAIG,MAAM,kD,GAExB,E,gLN0MwC,sBAAuB,e,YAIhCgB,EACrBC,EACFC,EACAC,EACAC,EACEC,EACAC,EAMAC,EAfN,MAAO,C,GAGoBP,EAJV,SAKXC,EAAQnB,YAAY,GAAG,GACzBoB,EAAuB,EACvBC,EAAc,EACdC,EAAa,EACXC,EAAaL,EAAY,QAAQ,CAAC,GAAG,CAAC,Y,OAAcQ,CAAgB,CAA3BC,EAAAA,IAAI,CAA8B,A,GAC3EH,EAAgB,IAAIpE,EAA6B,SAACwE,CAAK,EAIzD,OAHIA,EAAM,MAAM,CAAGR,GACfA,CAAAA,EAAuBQ,EAAM,MAAM,AAAD,EInSnC,CACH,SJoSkBA,EInSlB,UAAWjE,EJmSOiE,EIlStB,CJmSA,GACMH,EAAUP,EAAY,QAAQ,CAAC,GAAG,CAAC,SAACW,CAAQ,CAAEC,CAAK,EACrD,IAAMC,EAAqBrD,EAAUmD,GAE/BG,EAASC,AADK9C,EAAS4C,GACF,GAAG,CAACH,SAAAA,CAAK,E,OAAIJ,EAAc,GAAG,CAACI,E,GAO1D,OANIL,CAAU,CAACO,EAAM,CAAGT,GACpBA,CAAAA,EAAcE,CAAU,CAACO,EAAM,AAAD,EAE9BE,EAAO,MAAM,CAAGV,GAChBA,CAAAA,EAAaU,EAAO,MAAM,AAAD,EAEtB,CACHH,SAAAA,EACAG,OAAAA,EACA,SAAUT,CAAU,CAACO,EAAM,CAC3B,UAAWnE,EAAYoE,GACvB,UAAWb,EAAY,QAAQ,CAACY,EAAM,CAAC,IAAI,AAC/C,CACJ,GACArD,EAAkB,QAAiC,OAA1BuB,YAAY,GAAG,GAAKmB,EAAM,+BAC5C,CAAEM,QAAAA,EAASL,qBAAAA,EAAsBC,YAAAA,EAAaC,WAAAA,CAAW,G,GAjCpE,I,qHO1TkB,AAAsCY,KAAK,GAAG,GAIhE,IAAMhB,GPmQ4BnE,EOpQG2C,K,iBPqQ7BoC,EAMIK,EAEEC,EAMAC,EAyBHC,E,iDArCH,G,sBAAIvF,AAAaU,SAAbV,EACA,MAAM,AAAImD,MAAM,0BAKT,OAFPiC,EAAanC,YAAY,GAAG,GAErB,C,EAAMuC,EAAAA,EAAU,CAAC,cAAe,EAAG,CAC1CC,QAAAA,SAAQC,CAAQ,EACZA,EAAS,iBAAiB,CAAC,UAC/B,CACJ,G,QAOS,OALHJ,EAAQD,AANRA,CAAAA,EAAK,UAMM,WAAW,CAAC,UAAW,YAAY,WAAW,CAAC,WAEhE3D,EAAkB,QAAsC,OAA/BuB,YAAY,GAAG,GAAKmC,EAAW,wBACxDA,EAAanC,YAAY,GAAG,GAEnB,C,EAAMqC,EAAM,GAAG,CAACtF,G,WAAzB+E,EAAS,SAETrD,EAAkB,QAAsC,OAA/BuB,YAAY,GAAG,GAAKmC,EAAW,+BACxDA,EAAanC,YAAY,GAAG,GAExB8B,AAAUrE,SAAVqE,EAAAA,MAAAA,C,KAEQ,OADRrD,EAAiB,cACT,C,EAAMc,I,eAAduC,EAAQ,S,iBAGEY,E,iDACO,O,EAAMA,AADbA,CAAAA,EAAaN,EAAG,WAAW,CAAC,UAAW,aAAa,WAAW,CAAC,UAAS,EACjD,UAAU,G,QACxC,O,EAAMO,QAAQ,GAAG,CAACC,AADL,SACU,GAAG,CAAC1F,SAAAA,CAAC,E,OAAIwF,EAAW,MAAM,CAACxF,E,YAClD,OADA,SACA,C,EAAMwF,EAAW,GAAG,CAACZ,EAAO/E,G,eAA5B,S,MACJ,K,iDASI,OAHLuF,EAAAA,EAAAA,IAAAA,GAEHO,EAAQ,IAAI,CAAC,qCAAsCP,GAC3C,C,EAAM/C,I,eAAduC,EAAQ,S,aAEZ,MAAO,C,EAAAgB,SAAAA,CAAM,E,OAAIC,AAvMrB,SAAgB7B,CAAkC,CAAE8B,CAAyF,E,IAAvFC,EAAFD,EAAEC,mBAAmB,CAAEC,EAAvBF,EAAuBE,UAAU,CAAEC,EAAnCH,EAAmCG,iBAAiB,CAAEC,EAAtDJ,EAAsDI,mBAAmB,CACnHjC,EAAQnB,YAAY,GAAG,GAEvBZ,EAAUV,EAAUuE,GAE1B,GAAI7D,AAAY,KAAZA,EACA,MAAO,EAAE,CAGb,IAAIiE,EAAsB,EACpBC,EAAgBnE,EAASC,GAAS,GAAG,CAAC,SAACwC,CAAK,EAE9C,OADAyB,EAAsBjF,KAAK,GAAG,CAACiF,EAAqBzB,EAAM,MAAM,EIhG7D,CAAE,SAAU2B,AAXhB,SAAuB3B,CAAa,EACvC4B,AAAAA,GAAAA,EAAAA,CAAAA,AAAAA,EAAO5B,EAAM,MAAM,EAAI,GAAK,gCAE5B,IAAK,IADC6B,EAAW,IAAIC,YAAY,OAAO,IAAI,CAAC,GACpC7F,EAAI,EAAGA,EAAI+D,EAAM,MAAM,CAAE/D,IAAK,CACnC,IAAM8F,EAAO/B,EAAM,UAAU,CAAC/D,EAC9B4F,CAAAA,CAAQ,CAACE,EAAK,CAAGF,CAAQ,CAACE,EAAK,CAAI,GAAK9F,CAC5C,CACA,OAAO4F,CACX,EJoGwB7B,GIjGqB,OAAQA,AJiG7BA,EIjGmC,MAAM,CAAE,UAAWjE,EJiGtDiE,EIjGyE,CJkG7F,GAEMgC,EAAoB,EAAE,CAGtBC,EAAgBP,AAAwBQ,EAAxBR,EAAc,MAAM,CACpCS,EAAmBT,EAAc,MAAM,CAAGlF,KAAK,GAAG,CAACkF,EAAc,MAAM,CAAEpC,EAAY,oBAAoB,EAEzG8C,EAAeC,MAAM,IAAI,CAAC,CAAE,OAAQH,CAAc,EAAG,W,OAAM,IAAIJ,YAAYL,EAJ/D,EAIiG,E,EAEnHrF,CAAAA,EAAiB,uBAAuB,CAAG,EAC3CA,EAAiB,sBAAsB,CAAG,EAE1C,IAAMkG,EAAmBvG,EAAYyB,GAEjC+E,EAAsB,EACtBC,EAAuB,EAEbC,EAAAA,GAAAA,EAAAA,GAAAA,EAAAA,O,IAAd5C,EAAS,QAAK4C,EAAAA,EAAiCnD,EAAY,OAAO,CAAC,OAAO,EAAE,CAAF,mBAA5DmD,CAAAA,CAAAA,EAAAA,AAAAA,CAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,AAAAA,EAAAA,EAAAA,GAAgE,CAAhEA,IAAAA,EAAAA,EAAAA,EAAAA,KAAAA,CAAAA,GAAOC,EAAAA,CAAAA,CAAAA,EAAAA,CAAgBC,EAAAA,CAAAA,CAAAA,EAAAA,CACjC,IAAI,EAACpB,IKtIkBqB,ELsIkBD,EAAM,SAAS,CKrI5D,AAAI,AAA2B,UAA3B,OAAOC,EACAnG,EAAyB,QAAQ,CAACmG,GAEtClG,EAA4B,QAAQ,CAACkG,GLkIgB,GAKxD,GADAJ,IACInG,EAASiG,EAAoBA,EAAmBK,EAAM,SAAS,EApBrD,EAoBqE,CAE/EJ,IACA,QACJ,CAEA,IAAMM,EAA4BH,EAAiBpD,EAAY,OAAO,CAAC,MAAM,CAG7E,IAAI0C,CAAAA,EAAQ,MAAM,GAAKV,GAAcwB,CAnEf/F,EAmEoC,CACtD4F,MAAAA,EACA,qBAAsB,EACtB,wBAAyB,EACzB,mBAAoBA,EAAM,QAAQ,CAAGrD,EAAY,WAAW,CAC5DuD,yBAAAA,EACA,oCAAqC,EACrC,6BAA8B,EAC9B,uBAAwBF,CAAAA,CAAAA,EAAM,SAAS,GAAKnB,CAAkB,CAClE,EA5EiCuB,EA4E9Bf,CAAO,CAACA,EAAQ,MAAM,CAAG,EAAE,CA3E3B1E,EAAcP,GAAKO,EAAcyF,GA2EF,KAIlC,IAAIC,EAAa,EACbC,EAAgB,EAChBC,EAAoB,EAEpBC,EAAsB,GACtBC,EAAmB,EAElBC,EAAAA,GAAAA,EAAAA,GAAAA,EAAAA,O,IAAL,QKxKuBT,ELiFD7F,EAAWgG,EAuF5BM,EAAAA,EAAqC3B,EAAc,OAAO,EAAE,CAAF,mBAA1D2B,CAAAA,CAAAA,EAAAA,AAAAA,CAAAA,EAAAA,EAAAA,IAAAA,EAAAA,EAAAA,IAAAA,AAAAA,EAAAA,EAAAA,GAA8D,CAA9DA,IAvFiBtG,EAAWgG,EAuF5BM,EAAAA,EAAAA,EAAAA,KAAAA,CAAAA,GAAOC,GAAAA,CAAAA,CAAAA,EAAAA,CAAmBC,GAAAA,CAAAA,CAAAA,EAAAA,CACvBC,GAAkBtB,EAClBuB,GAAqBjH,KAAK,GAAG,CAACkF,EAAc,MAAM,CAAEpC,EAAY,oBAAoB,EACpFoE,GAAuB,GACvBC,GAAAA,KAAAA,EAECC,GAAAA,GAAAA,GAAAA,GAAAA,GAAAA,O,IAAL,QAAKA,GAAAA,GAAuCjB,EAAM,MAAM,CAAC,OAAO,EAAE,CAAF,mBAA3DiB,CAAAA,CAAAA,GAAAA,AAAAA,CAAAA,GAAAA,GAAAA,IAAAA,EAAAA,EAAAA,IAAAA,AAAAA,EAAAA,GAAAA,GAA+D,CAA/DA,IAAAA,GAAAA,EAAAA,GAAAA,KAAAA,CAAAA,GAAOC,GAAAA,EAAAA,CAAAA,EAAAA,CAAiBC,GAAAA,EAAAA,CAAAA,EAAAA,CACnBC,GAAeC,AI9G9B,SAAeC,CAAkB,CAAEV,CAAc,CAAErB,CAAiB,CAAEgC,CAA6B,EACtG,IAAIC,EAAYjC,EAAY,EAE5B,GAAIA,EAAY,EACZ,OAAOiC,EAIX,GADA/H,EAAiB,uBAAuB,GACpCC,EAASkH,EAAO,SAAS,CAAIU,EAAS,SAAS,CAAGV,EAAO,SAAS,EAAKrB,EAEvE,OADA9F,EAAiB,sBAAsB,GAChC+H,EAGX,IAAK,IAAIC,EAAS,EAAGA,GAAUlC,EAAWkC,IACtCF,CAAc,CAACE,EAAO,CAAC,IAAI,CAAC,GAC5BF,CAAc,CAACE,EAAO,CAAC,EAAE,CAAI,IAAKA,CAAK,EAAK,EAKhD,IAAK,IAFCC,EAAY,GAAMd,EAAO,MAAM,CAAG,EAE/Be,EAAI,EAAGA,GAAMf,EAAO,MAAM,CAAGrB,EAAYoC,IAAK,CACnD,IAAIC,EAAAA,KAAAA,EAEAA,EADAD,EAAI,EAAIL,EAAS,QAAQ,CAAC,MAAM,CACpBV,EAAO,QAAQ,CAACU,EAAS,QAAQ,CAAC,UAAU,CAACK,EAAI,GAAG,CAGpD,EAGhB,IAAK,IAAIE,EAAS,EAAGA,GAAUtC,EAAWsC,IAQtC,GAPIA,AAAW,IAAXA,EACAN,CAAc,CAAC,EAAE,CAACI,EAAE,CAAI,AAACJ,CAAAA,CAAc,CAAC,EAAE,CAACI,EAAI,EAAE,EAAI,EAAK,GAAKC,EAG/DL,CAAc,CAACM,EAAO,CAACF,EAAE,CAAK,AAACJ,CAAAA,CAAc,CAACM,EAAO,CAACF,EAAI,EAAE,EAAI,EAAK,GAAKC,EAAgBL,CAAAA,CAAAA,CAAc,CAACM,EAAS,EAAE,CAACF,EAAI,EAAE,CAAGJ,CAAc,CAACM,EAAS,EAAE,CAACF,EAAC,GAAM,EAAK,GAAKJ,CAAc,CAACM,EAAS,EAAE,CAACF,EAAI,EAAE,CAG1MJ,CAAAA,CAAc,CAACM,EAAO,CAACF,EAAE,CAAGD,CAAQ,GAAO,IAC5CF,EAAY3H,KAAK,GAAG,CAAC2H,EAAW3H,KAAK,GAAG,CAACA,KAAK,GAAG,CAAC8H,EAAIf,EAAO,MAAM,EAAGiB,IACtEtC,EAAY1F,KAAK,GAAG,CAAC0F,EAAWsC,GAC5BL,AAAc,IAAdA,GACA,OAAOA,CAIvB,CACA,OAAOA,CACX,EJ+D2CL,GAAYP,GAxDjC,EAwDoDnB,GACpDqC,GAAiBjI,KAAK,GAAG,CAAC8G,GAAoBO,IAC9Ca,GAAwBlI,KAAK,GAAG,CAACsH,GAAW,QAAQ,CAAC,MAAM,CAAGP,GAAO,MAAM,EAAIQ,IAAiB,EAClGA,CAAAA,GAAeP,IAAoBO,IAAgBP,IAAmBiB,GAAiBhB,IAAwBM,IAAgBP,IAAmBiB,IAAkBhB,IAAsBiB,GAAwBhB,EAAmB,IACrOF,GAAkBO,GAClBN,GAAqBgB,GACrBf,GAAuBgB,GACvBf,GAAuBE,GAE/B,C,UAVKD,GAAAA,GAAAA,GAAAA,C,aAAAA,IAAAA,AAAAA,MAAAA,GAAAA,MAAAA,EAAAA,GAAAA,MAAAA,E,YAAAA,G,MAAAA,E,EAqBL,GATAZ,GAAcQ,GACdP,GAAiBQ,GACjBP,GAAqBQ,GAAAA,GACQ7H,SAAzB8H,KACAP,GAAoBD,CAAAA,CAAAA,GAAuBQ,EAAmB,EAC9DR,EAAsBQ,IAItB3B,EAAQ,MAAM,GAAKV,GAAcwB,CAlHnB/F,EAkHwC,CACtD4F,MAAAA,EACA,qBAAsBK,EAAaf,EACnC,wBAAyBgB,EAAgBd,EACzC,mBAAoBQ,EAAM,QAAQ,CAAGrD,EAAY,WAAW,CAC5DuD,yBAAAA,EACA,oCAAqCK,EAAoBxB,EAAc,MAAM,CAC7E,6BAA8B0B,EAAmB1B,EAAc,MAAM,CACrE,uBAAwBiB,CAAAA,CAAAA,EAAM,SAAS,GAAKnB,CAAkB,CAClE,EA3H6BuB,EA2H1Bf,CAAO,CAACA,EAAQ,MAAM,CAAG,EAAE,CA1H/B1E,EAAcP,GAAKO,EAAcyF,GA0HE,GAC9B,SAASlD,CAEjB,C,UAvCKwD,EAAAA,GAAAA,EAAAA,C,aAAAA,GAAAA,AAAAA,MAAAA,EAAAA,MAAAA,EAAAA,EAAAA,MAAAA,E,YAAAA,E,MAAAA,C,EAyCL,IAAIL,CAAAA,GAActB,AAAwBQ,EAAxBR,EAAc,MAAM,AAAiB,GAiBvD,IAAK,IAjJ4BqB,GAqI3BnH,GAAiB,CACnB+G,MAAAA,EACA,qBAAsBK,EAAaf,EACnC,wBAAyBgB,EAAgBd,EACzC,mBAAoBQ,EAAM,QAAQ,CAAGrD,EAAY,WAAW,CAC5DuD,yBAAAA,EACA,oCAAqCK,EAAoBxB,EAAc,MAAM,CAC7E,6BAA8B0B,EAAmB1B,EAAc,MAAM,CACrE,uBAAwBiB,CAAAA,CAAAA,EAAM,SAAS,GAAKnB,CAAkB,CAClE,EAEImD,GAAAA,KAAAA,EACKC,GAAepI,KAAK,GAAG,CAACwF,EAAQ,MAAM,CAAEV,GAAasD,IAAgB,EAAGA,KAC7E,GAAI5C,EAAQ,MAAM,EAAI4C,IAAgB9B,AAAsD,GAlJ/DC,GAkJsCf,CAAO,CAAC4C,GAAa,CAjJzFtH,EAiJ4D1B,IAjJzC0B,EAAcyF,KAkJ5B4B,GAAcC,QAGd,KAGJD,AAAgB9I,UAAhB8I,IACA3C,EAAQ,MAAM,CAAC2C,GAAa,EAAG/I,IAE/BoG,EAAQ,MAAM,CAAGV,GACjBU,EAAQ,GAAG,KAEnB,C,UA3GcS,EAAAA,GAAAA,EAAAA,C,aAAAA,GAAAA,AAAAA,MAAAA,EAAAA,MAAAA,EAAAA,EAAAA,MAAAA,E,YAAAA,E,MAAAA,C,EAuHd,OAVA9F,EAAMP,GACNO,EAAM,CAAE,MAAO6F,EAAsB,MAAOD,CAAoB,GAEhE5F,EAAMqF,EAAQ,GAAG,CAACpG,SAAAA,CAAM,M,aAAK,A,iaAAA,GACtBA,G,IAAAA,CACH,cAAe0B,EAAc1B,E,gVAGjCiB,EAAkB,QAAiC,OAA1BuB,YAAY,GAAG,GAAKmB,EAAM,0BAE5CyC,EAAQ,GAAG,CAACpG,SAAAA,CAAM,E,OAAIA,EAAO,KAAK,A,EAC7C,EAgD4BsE,EAAOgB,E,KACnC,MO/SA2D,UAAY,SAAOC,CAAO,M,qrCACP,O,EAAMxF,E,eACrByF,YAAY5D,AADG,SACI2D,EAAQ,IAAI,G,MACnC,E,0ZCXA,EAAoB,CAAC,CAAG,CAACE,EAAS,KACjC,IAAI,IAAI,KAAO,EACL,EAAoB,CAAC,CAAC,EAAY,IAAQ,CAAC,EAAoB,CAAC,CAACA,EAAS,IACzE5J,OAAO,cAAc,CAAC4J,EAAS,EAAK,CAAE,WAAY,GAAM,IAAK,CAAU,CAAC,EAAI,AAAC,EAGzF,ECNA,EAAoB,CAAC,CAAG,CAAC,EAGzB,EAAoB,CAAC,CAAG,AAAC,GACjBjE,QAAQ,GAAG,CACjB3F,OAAO,IAAI,CAAC,EAAoB,CAAC,EAAE,MAAM,CAAC,CAAC,EAAU,KACpD,EAAoB,CAAC,CAAC,EAAI,CAAC,EAAS,GAC7B,GACL,EAAE,GCPP,EAAoB,CAAC,CAAG,AAAC,GAIhB,GAAK,EAAU,MCLxB,EAAoB,CAAC,CAAG,AAAC,MACxB,GAAI,AAAsB,UAAtB,OAAO6J,WAAyB,OAAOA,WAC3C,GAAI,CACH,OAAO,IAAI,EAAI,AAAIC,SAAS,gBAC7B,CAAE,MAAOF,EAAG,CACX,GAAI,AAAkB,UAAlB,OAAOG,OAAqB,OAAOA,MACxC,CACD,KCPA,EAAoB,CAAC,CAAG,CAAC,EAAK,IAAU/J,OAAO,SAAS,CAAC,cAAc,CAAC,IAAI,CAAC,EAAK,G,MCAlF,IAAI,EAAW,EAAE,AACjB,GAAoB,CAAC,CAAG,CAAC,EAAQ,EAAU,EAAI,KAC9C,GAAI,EAAU,CACb,EAAW,GAAY,EACvB,IAAK,IAAIa,EAAI,EAAS,MAAM,CAAEA,EAAI,GAAK,CAAQ,CAACA,EAAI,EAAE,CAAC,EAAE,CAAG,EAAUA,IACrE,CAAQ,CAACA,EAAE,CAAG,CAAQ,CAACA,EAAI,EAAE,AAC9B,EAAQ,CAACA,EAAE,CAAG,CAAC,EAAU,EAAI,EAAS,CACtC,MACD,CAEA,IAAK,IADD,EAAe,IACVA,EAAI,EAAGA,EAAI,EAAS,MAAM,CAAEA,IAAK,CAGzC,IAAK,GAFD,CAAC,EAAU,EAAI,EAAS,CAAG,CAAQ,CAACA,EAAE,CACtC,EAAY,GACP,EAAI,EAAG,EAAI,EAAS,MAAM,CAAE,IAEnC,AAAC,CAAY,GAAZ,GAAwB,GAAgB,CAAO,GAChDb,OAAO,IAAI,CAAC,EAAoB,CAAC,EAAE,KAAK,CAAC,AAAC,GAAS,EAAoB,CAAC,CAAC,EAAI,CAAC,CAAQ,CAAC,EAAE,GAEzF,EAAS,MAAM,CAAC,IAAK,IAErB,EAAY,GACR,EAAW,GAAc,GAAe,CAAO,GAGrD,GAAI,EAAW,CACd,EAAS,MAAM,CAACa,IAAK,GACrB,IAAI,EAAI,GACJ,AAAM,UAAN,GAAiB,GAAS,EAC/B,CACD,CACA,OAAO,CACR,C,KC/BA,EAAoB,EAAE,CAAG,IAAO,S,MCAhC,IAAI,EAAO,EAAoB,CAAC,AAChC,GAAoB,CAAC,CAAG,IACf8E,QAAQ,GAAG,CAAC,CAAC,KAAK,MAAM,MAAM,CAAC,GAAG,CAAC,EAAoB,CAAC,CAAE,IAAsB,IAAI,CAAC,E,WCA1F,EAAoB,CAAC,CAAC,aAAa,EAAE,GAAY,EAAoB,CAAC,CAAC,QAAQ,CAAG,EAAC,EACvF,IAHI,EAGA,EAAW,EAAoB,CAAC,CAAC,QAAQ,CAC7C,GAAI,CAAC,GAAa,IAIZ,EAAS,aAAa,EAAI,AAAiD,WAAjD,EAAS,aAAa,CAAC,OAAO,CAAC,WAAW,IAAiB,GAAY,EAAS,aAAa,CAAC,GAAG,AAAD,EAC1H,CAAC,GAAW,CACd,IAAI,EAAU,EAAS,oBAAoB,CAAC,UAC5C,GAAI,EAAQ,MAAM,CAEhB,IADA,IAAI,EAAI,EAAQ,MAAM,CAAG,EAClB,EAAI,IAAO,EAAC,GAAa,CAAC,aAAa,IAAI,CAAC,EAAS,GAAI,EAAY,CAAO,CAAC,IAAI,CAAC,GAAG,AAEhG,CAKF,GAAI,CAAC,EAAW,MAAM,AAAIzC,MAAM,wDAEhC,GAAoB,CAAC,CADrB,EAAY,EAAU,OAAO,CAAC,SAAU,IAAI,OAAO,CAAC,OAAQ,IAAI,OAAO,CAAC,QAAS,IAAI,OAAO,CAAC,YAAa,I,WCrB1G,IAAI,EAAkB,CAAC,IAAO,CAAE,CAchC,GAAoB,CAAC,CAAC,CAAC,CAAG,CAAC,EAAS,KAGtB,AAAC,CAAe,CAAC,EAAQ,EAEzB8G,cAAc,EAAoB,CAAC,CAAG,EAAoB,CAAC,CAAC,GAI1E,EAEA,IAAI,EAAqBC,KAAK,kBAAqB,CAAGA,KAAK,kBAAqB,EAAI,EAAE,CAClF,EAA6B,EAAmB,IAAI,CAAC,IAAI,CAAC,EAC9D,GAAmB,IAAI,CAzBJ,AAAC,IAChB,GAAI,CAAC,EAAU,EAAa,EAAQ,CAAG,EACvC,IAAK,IAAI,KAAY,EACb,EAAoB,CAAC,CAAC,EAAa,IACnC,GAAoB,CAAC,CAAC,EAAS,CAAG,CAAW,CAAC,EAAS,AAAD,EAI9D,IADI,GAAS,EAAQ,GACd,EAAS,MAAM,EAAE,CAAe,CAAC,EAAS,GAAG,GAAG,CAAG,EAC1D,EAA2B,EAC/B,C,KCZA,EAAoB,IAAI,CAAG,wB"}